<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Analyses on Wotecki et al. (2020) - Annual Review of Nutrition - Supplementary Materials</title>
    <link>/analyses/</link>
    <description>Recent content in Analyses on Wotecki et al. (2020) - Annual Review of Nutrition - Supplementary Materials</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="/analyses/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Interactive Timeline of Nutrition, Food and Health</title>
      <link>/analyses/timelines/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/analyses/timelines/</guid>
      <description>The main goal of Dr. Woteki’s conference speech and our team’s subsequent paper in the Annual Review of Nutrition was to provide a historical overview of important events both before and after the 1969 White House Conference on Food, Nutrition and Health by looking more closely at five general domains: the social environment, the food environment, nutrition science, public health data, and policy events.</description>
    </item>
    
    <item>
      <title>Text Network of 1969 White House Conference Report</title>
      <link>/analyses/text-network/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/analyses/text-network/</guid>
      <description>In the second section of our paper, we examined what policy makers discussed in the 1969 White House Conference. To garner some high-level insights, we used tidytext – a package developed for natural language processing in the R open-source software language – to visualize a network of textual relations in the WHC Report. This process entails cleaning and preprocessing the textual data from the WHC Report (i.e. selective lemmatization and removal of stop words), quantifying the number of unique words in the corpus, constructing bigrams based on how many times words co-occur adjacent to one another in the text, and then constructing a network of textual relations comprised of the nodes and word co-occurrences.</description>
    </item>
    
  </channel>
</rss>